{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from matplotlib import pyplot as plt #Use for image debugging\n",
    "import torch \n",
    "from torchvision import models, transforms #Need this to get VGG-11\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed batches (based on James' code)\n",
    "# The original data is organize slightly differently so it's somewhat messy. Sorry. \n",
    "\n",
    "def load_processed_batches(path, test = 0):\n",
    "    #Path is the directory where the files of interest are\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    print('Loading data...')\n",
    "    if path == 'cifar10_dataset/cifar-10-batches-py':\n",
    "        #The original data is in its own folder with some extra files\n",
    "        #So we only loop through the ones that we care about \n",
    "        files = os.listdir(path)\n",
    "        files2 = []\n",
    "        for i in range(len(files)): #If we want train data\n",
    "            if test == 0: \n",
    "                if 'data_batch' in files[i]: \n",
    "                    files2.append(files[i])\n",
    "            else: \n",
    "                if 'test_batch' in files[i]: \n",
    "                    files2.append(files[i])\n",
    "        for file in tqdm.tqdm(files2): #If we want test data\n",
    "            with open(os.path.join(path, file), 'rb') as f:\n",
    "                processed_batch_dict = pickle.load(f, encoding='bytes')\n",
    "                data.append(processed_batch_dict[b'data'])\n",
    "                labels.append(processed_batch_dict[b'labels'])\n",
    "        \n",
    "        #Store the data and labels \n",
    "        data = np.concatenate(data)\n",
    "        data = data.astype(np.float32) / 255 #Divide by 255 to get into 0 to 1 range \n",
    "        labels = np.concatenate(labels)\n",
    "        \n",
    "        #Reshape to the same dimensions as the processed data\n",
    "        data = data.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "\n",
    "    else: #If we're using black boxes or Gaussian noise data \n",
    "        if test == 1: path = path + '_test' \n",
    "        files = os.listdir(path)\n",
    "        for file in tqdm.tqdm(files):\n",
    "            with open(os.path.join(path, file), 'rb') as f:\n",
    "                processed_batch_dict = pickle.load(f, encoding='bytes')\n",
    "                data.append(processed_batch_dict['data'])\n",
    "                labels.append(processed_batch_dict['labels'])\n",
    "        #Store the data and labels \n",
    "        data = np.concatenate(data)\n",
    "        data = data.astype(np.float32) / 255 #Divide by 255 to get into 0 to 1 range \n",
    "\n",
    "        labels = np.concatenate(labels)\n",
    "        labels = np.repeat(labels,9) #assume that the same image is repeated 9 times for each of the superpixels (3-by-3)\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 51.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [0.32768 0.32768 0.32768]\n",
      "Std Dev: [0.27755317 0.26929596 0.26811677]\n"
     ]
    }
   ],
   "source": [
    "# Set up the transformation for the data \n",
    "\n",
    "# Normalize images via the statistics of the original dataset\n",
    "path = 'cifar10_dataset/cifar-10-batches-py'\n",
    "processed_images, _ = load_processed_batches(path,test=0)\n",
    "\n",
    "imMean = np.mean(processed_images.reshape(-1,3),axis=0)\n",
    "imStd = np.std(processed_images.reshape(-1,3),axis=0)\n",
    "\n",
    "print('Mean:',imMean)\n",
    "print('Std Dev:', imStd)\n",
    "\n",
    "#Set-up normalization\n",
    "normalize = transforms.Normalize(mean=imMean,std=imStd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 31.89it/s]\n"
     ]
    }
   ],
   "source": [
    "#Get data and format it for training \n",
    "path = 'processed_batches_boxes' #cifar10_dataset/cifar-10-batches-py'\n",
    "processed_images, processed_labels = load_processed_batches(path,test=0)\n",
    "processed_images = processed_images.transpose(0,3,1,2) #Get into the appropriate shape for training\n",
    "\n",
    "trainData, valData, trainLabel, valLabel = train_test_split(processed_images, processed_labels, test_size=0.2, random_state=42)\n",
    "train_set = torch.utils.data.TensorDataset(normalize(torch.tensor(trainData)),torch.tensor(trainLabel).type(torch.LongTensor))\n",
    "val_set = torch.utils.data.TensorDataset(normalize(torch.tensor(valData)),torch.tensor(valLabel).type(torch.LongTensor))\n",
    "\n",
    "#Get data and format it for testing \n",
    "processed_images, processed_labels = load_processed_batches(path,test=1)\n",
    "processed_images = processed_images.transpose(0,3,1,2) #Get into the appropriate shape for training\n",
    "test_set = torch.utils.data.TensorDataset(normalize(torch.tensor(processed_images)),torch.tensor(processed_labels).type(torch.LongTensor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "batch_size = 64 \n",
    "num_classes = 10 \n",
    "momentum = 0.9 \n",
    "learning_rate = 0.005 \n",
    "weight_decay = 0.005 \n",
    "num_epochs = 20\n",
    "num_workers = 2\n",
    "\n",
    "# Starting parameters from: https://blog.paperspace.com/alexnet-pytorch/ \n",
    "\n",
    "#Set-up dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers = num_workers)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers = num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers = num_workers)\n",
    "\n",
    "#Get model\n",
    "mod = models.vgg11(weights=None)\n",
    "mod.classifier[6].out_features = num_classes #Adjust final layer to have the right number of classes \n",
    "\n",
    "#Get device \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "mod.to(device)\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 5625.0000\n",
      "Accuracy of the network on validation images: 68.0911111111111 %\n",
      "Epoch [2/20], Loss: 5625.0000\n",
      "Accuracy of the network on validation images: 77.04666666666667 %\n",
      "Epoch [3/20], Loss: 5625.0000\n",
      "Accuracy of the network on validation images: 81.78222222222222 %\n",
      "Epoch [4/20], Loss: 5625.0000\n",
      "Accuracy of the network on validation images: 79.35111111111111 %\n",
      "Epoch [5/20], Loss: 5625.0000\n",
      "Accuracy of the network on validation images: 84.82222222222222 %\n",
      "Epoch [6/20], Loss: 5625.0000\n",
      "Accuracy of the network on validation images: 85.41444444444444 %\n",
      "Epoch [7/20], Loss: 5625.0000\n",
      "Accuracy of the network on validation images: 84.30555555555556 %\n",
      "Epoch [8/20], Loss: 5625.0000\n",
      "Accuracy of the network on validation images: 84.26555555555555 %\n",
      "Epoch [9/20], Loss: 5625.0000\n",
      "Accuracy of the network on validation images: 84.00222222222222 %\n",
      "Epoch [10/20], Loss: 5625.0000\n",
      "Accuracy of the network on validation images: 86.87777777777778 %\n",
      "Epoch [11/20], Loss: 5625.0000\n",
      "Accuracy of the network on validation images: 86.77333333333333 %\n",
      "Epoch [12/20], Loss: 5625.0000\n",
      "Accuracy of the network on validation images: 86.39777777777778 %\n",
      "Epoch [13/20], Loss: 5625.0000\n",
      "Accuracy of the network on validation images: 81.00777777777778 %\n",
      "Epoch [14/20], Loss: 5625.0000\n",
      "Accuracy of the network on validation images: 88.1211111111111 %\n",
      "Epoch [15/20], Loss: 5625.0000\n",
      "Accuracy of the network on validation images: 86.50111111111111 %\n",
      "Epoch [16/20], Loss: 5625.0000\n",
      "Accuracy of the network on validation images: 86.85555555555555 %\n",
      "Epoch [17/20], Loss: 5625.0000\n",
      "Accuracy of the network on validation images: 87.58888888888889 %\n",
      "Epoch [18/20], Loss: 5625.0000\n",
      "Accuracy of the network on validation images: 84.79444444444445 %\n",
      "Epoch [19/20], Loss: 5625.0000\n",
      "Accuracy of the network on validation images: 85.99111111111111 %\n",
      "Epoch [20/20], Loss: 5625.0000\n",
      "Accuracy of the network on validation images: 86.66888888888889 %\n"
     ]
    }
   ],
   "source": [
    "#Training \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(mod.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=momentum)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = mod(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print ('Epoch [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, loss.item()))\n",
    "            \n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = mod(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "    \n",
    "        print('Accuracy of the network on validation images: {} %'.format(100 * correct / total)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on test images: 75.76666666666667 %\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = mod(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        del images, labels, outputs\n",
    "\n",
    "    print('Accuracy of the network on test images: {} %'.format(100 * correct / total)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
